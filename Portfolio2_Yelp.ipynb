{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3906bb2",
   "metadata": {},
   "source": [
    "## Analysis of Yelp Dataset Portfolio2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9492a4",
   "metadata": {},
   "source": [
    "The portfolio aims to use various data processing techniques to clean and preprocess the data, filter out irrelevant data, and remove any outliers that could impact the accuracy of the model. Finally, the portfolio aims to use linear regression models to train and validate the model's accuracy in predicting user ratings towards business. Ultimately, the objective is to build a reliable model that can be used to provide insights into user preferences and help businesses make data-driven decisions to improve their services and offerings. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use Yelp sub-dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c65efd",
   "metadata": {},
   "source": [
    "### Import the output sample data from Portfolio1\n",
    "The csv file named `Yelp_Portfolio2_Input.csv` is provided. You may need to use the Pandas method, i.e., `read_csv`, for doing this. After that, please import the csv file and print out its total length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba823cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Dylan Neilson\n",
    "# Student ID: 47004029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dbcf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import library to calculate MSE for Q3\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc01727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the datasheet:  38654\n"
     ]
    }
   ],
   "source": [
    "# Import datasheet\n",
    "sample_data = pd.read_csv('data/Yelp_Portfolio2_Input.csv')\n",
    "\n",
    "# Print length on datasheet\n",
    "print(\"The length of the datasheet: \", len(sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c3d9b",
   "metadata": {},
   "source": [
    "# Q1. `business_categories` processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b37b2",
   "metadata": {},
   "source": [
    "You may notice that there are a total of 693 unique business categories present in the sample data. Please write a code snippet to confirm this number. Then, generate a boxplot of `stars` for `business_categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0238816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique business categories:  693\n"
     ]
    }
   ],
   "source": [
    "# Confirm there are 693 unique business categories\n",
    "category_array = sample_data['business_categories'].unique()\n",
    "print(\"The number of unique business categories: \", category_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc2a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'stars'}, xlabel='business_categories'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generates a boxplot of stars for business_categories\n",
    "sample_data.boxplot(\"stars\",by = \"business_categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578c205",
   "metadata": {},
   "source": [
    "Sometimes we need to extract some major categories, such as `Middle Eastern; Restaurants` and `Sushi Bars; Restaurants`, both of which should belong to the `Restaurants` category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2aae2",
   "metadata": {},
   "source": [
    "### Q1.1 How to efficiently and accurately extract the last category value (i.e., categorieN) from the `business_categories` column in a dataset, where the format of each row is a semicolon-separated list of categories (i.e., 'categorie1; categorie2;...;categorieN')? and replace the original string with this last category value. At last, print the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcdd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row in sample_data\n",
    "for i in range(len(sample_data)): \n",
    "    # Get the categories for current row\n",
    "    categories = sample_data.at[i, 'business_categories']\n",
    "    # If semicolon exists, split the categories by semicolon\n",
    "    if ';' in categories:\n",
    "        split_categories = categories.split(';')\n",
    "        # Get the last category stored in split_categories and remove any spaces\n",
    "        last_category = split_categories[-1].split()[-1]\n",
    "        # Overwrite the category value for this row with last_category\n",
    "        sample_data.at[i, 'business_categories'] = last_category\n",
    "    else: \n",
    "        # If semicolon does not exist, remove the spaces in the string\n",
    "        sample_data.at[i, 'business_categories'] = categories.split()[-1]\n",
    "\n",
    "# Display first 5 rows of dataframe\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77d3c0",
   "metadata": {},
   "source": [
    "### Q1.2 Let's first check how many unique business categories are present in the dataset (output from Q1.1). Maybe it's still not an appropriate number to make a clear Boxplot. Now, we want to display `ALL Rows` of the business category count data. That is to count and print the number of occurrences for each business category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f87584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the amount of unique business categories in the cleaned data from Q1.1\n",
    "category_array = sample_data['business_categories'].unique()\n",
    "print(\"The number of unique business categories: \", category_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0169e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the number of occurances for each business category\n",
    "business_cat_count = sample_data['business_categories'].value_counts()\n",
    "\n",
    "# Display all rows of DataFrame\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# Print the number of occurances for each business category\n",
    "print(business_cat_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f446f",
   "metadata": {},
   "source": [
    "### Q1.3 We want to remove categories that appear fewer than 200 times. Write a Python code snippet to perform this operation. At last, print the number of resulting unique business_categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the number of occurances for each business category\n",
    "business_cat_count = sample_data['business_categories'].value_counts()\n",
    "\n",
    "# Store the number of businesses that appear more than 200 times\n",
    "business_count = business_cat_count[business_cat_count >= 200].index\n",
    "\n",
    "# Check each element in the 'business_categories' column sample_data is present in the business_count list\n",
    "sample_data = sample_data[sample_data['business_categories'].isin(business_count)]\n",
    "\n",
    "# Print the result\n",
    "print(\"business categories that occur more than 200 times: \", len(sample_data))\n",
    "\n",
    "# Display all rows of dataframe\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# Print the occurance of individual businesses\n",
    "print(business_cat_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649f53c",
   "metadata": {},
   "source": [
    "# Q2. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c649505",
   "metadata": {},
   "source": [
    "### Q2.1 Remove any rows from the sample_data DataFrame (output from Q1.3) where the `useful` column has a value of 6 or more; Then, create a single figure with two subplots, one showing the boxplot of `useful` column of the original data and the other showing the boxplot of the data with outliers removed. \n",
    "\n",
    "At last, __print the length of the data__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebeb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store rows from useful column that has a value less than 6 (This removes any values >6)\n",
    "useful_less_six_df = sample_data[sample_data['useful'] < 6]\n",
    "\n",
    "# Create a single figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize = (10, 5))\n",
    "\n",
    "# Create first subplot for the orginal data\n",
    "axs[0].boxplot(sample_data['useful'])\n",
    "axs[0].set_title('Original Data')\n",
    "\n",
    "# Create second subplot for the cleaned data\n",
    "axs[1].boxplot(useful_less_six_df['useful'])\n",
    "axs[1].set_title('Data After Removing Values of 6 or more')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result\n",
    "print(\"Length of cleaned data: \", len(useful_less_six_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29233a",
   "metadata": {},
   "source": [
    "### Q2.2 In general, we might remove some inactive users from a dataset (output from Q2.1), for example, users who rate businesses less than 3 times. However, in this case, we are doing the opposite and removing extremely active users who rate businesses more than 30 times (>30). Again, create a single figure with two subplots, one showing the boxplot of the count of business rating given by each user and the other showing the boxplot of the data with outliers removed. \n",
    "\n",
    "At last, __print the length of the data__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb385f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and count the number of reviews by each user in useful_less_six_df\n",
    "user_group_df = useful_less_six_df.groupby(['user_id'])['stars'].count().reset_index(name = \"count\")\n",
    "\n",
    "# Store number of users who rate the business 30 times or less (This removes any values >30)\n",
    "userIDs = user_group_df[user_group_df['count'] <= 30]['user_id'].tolist()\n",
    "\n",
    "# Store rows from useful column that only include the users that exist in userIDs\n",
    "userid_outliers_removed_df = useful_less_six_df[useful_less_six_df['user_id'].isin(userIDs)]\n",
    "\n",
    "# Create a single figure with two subplots\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "# Create first subplot for the orginal data\n",
    "axs[0].boxplot(useful_less_six_df['useful'])\n",
    "axs[0].set_title('Data Before Removing Users')\n",
    "\n",
    "# Create second subplot for the cleaned data\n",
    "axs[1].boxplot(userid_outliers_removed_df['useful'])\n",
    "axs[1].set_title('Data After removing Users')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd105ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result\n",
    "print(\"Length of cleaned data: \", len(userid_outliers_removed_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95827eb7",
   "metadata": {},
   "source": [
    "# Q3. Training a LinearRegression model on the data output from Q2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4568bd",
   "metadata": {},
   "source": [
    "### Q3.1 How to build a linear regression model on a subset of the data, using the `useful` column as the input variable and the `stars` column as the output variable. Split the data into a training set and a test set, with 70% of the data used for training. The random_state is set to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y input\n",
    "X = userid_outliers_removed_df[['useful']]\n",
    "y = userid_outliers_removed_df['stars']\n",
    "\n",
    "# Split dataset into training and testing sets, 30% for testing and 70% for training, fixed random seed of 42.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create linear regression object\n",
    "reg = linear_model.LinearRegression()\n",
    "# Train regression model reg on the training set (X_train and y_train).\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predicitons on the test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Calculate MSE on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# Calculate RMSE on the test set\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print MSE and RMSE\n",
    "print('MSE is: ', mse)\n",
    "print('RMSE is: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863d87e",
   "metadata": {},
   "source": [
    "### Q3.2 Assuming that the number of reviews a business has received  `business_review_count`  can greatly influence the average rating that the business has received. Now, we create the relevant variable to the data, and do the LinearRegression again to the `stars`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rows in DataFrame by business ID, count number of reviews for each business, save the results in review_counts.\n",
    "review_counts = userid_outliers_removed_df.groupby('business_id')['text'].count().reset_index()\n",
    "# Renames 'text' column in the review_counts DataFrame\n",
    "review_counts = review_counts.rename(columns={'text': \"business_review_count\"})\n",
    "# Display first 5 rows of review_counts DataFrame\n",
    "review_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b99240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame and merge userid_outliers_removed_df DataFrame with review_counts DataFrame on 'business_id' column\n",
    "new_data = pd.merge(userid_outliers_removed_df, review_counts, on='business_id')\n",
    "\n",
    "# Define X and y input\n",
    "X = new_data[['business_review_count']]\n",
    "y = new_data['stars']\n",
    "# Split dataset into training and testing sets, 30% for testing and 70% for training, fixed random seed of 42.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create linear regression object\n",
    "reg = linear_model.LinearRegression()\n",
    "# Train regression model reg on the training set (X_train and y_train).\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Calculate MSE on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# Calculate RMSE on the test set\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print MSE and RMSE\n",
    "print('MSE is: ', mse)\n",
    "print('RMSE is: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417bf155",
   "metadata": {},
   "source": [
    "### Q3.3 Output the correlations between `business_review_count` and `useful` variables with `stars` and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlation coefficient between 'business_review_count' column and the 'stars' column\n",
    "new_data['business_review_count'].corr(new_data['stars'])\n",
    "# Find the correlation coefficient between 'useful' column and 'stars' column\n",
    "new_data['useful'].corr(new_data['stars'])\n",
    "\n",
    "# Print the correlation coefficient between the 'business_review_count' column and the 'stars' column\n",
    "print(\"Correlations between bussiness_review_count and stars: \", new_data['business_review_count'].corr(new_data['stars']))\n",
    "# Print the correlation coefficient between the 'useful' column and 'stars' column\n",
    "print(\"Correlations between useful and stars: \", new_data['useful'].corr(new_data['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Analysis\n",
    "\n",
    "# If the correlation coefficient is positive, it indicates a positive relationship between the input and output \n",
    "# variables, and if it is negative, it indicates a negative relationship. A larger coefficient value indicates \n",
    "# a stronger correlation, while a smaller value indicates a weaker correlation, as in the case of the correlation \n",
    "# between 'useful' and 'stars'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
